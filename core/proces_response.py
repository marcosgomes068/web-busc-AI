"""
M√≥dulo de Processamento Multi-Agente
====================================

Este m√≥dulo gerencia o processamento de conte√∫do coletado usando
m√∫ltiplos agentes especializados de IA para an√°lise aprofundada.

Funcionalidades:
- Sistema multi-agente com 4 especialistas
- Processamento sequencial e estruturado
- Gera√ß√£o de resumos parciais e s√≠ntese final
- Relat√≥rios detalhados e estat√≠sticas
- Tratamento robusto de dados JSON

Agentes Especializados:
- Resumidor: Extrai pontos principais
- Analista: Identifica insights e tend√™ncias
- Organizador: Estrutura informa√ß√µes logicamente
- Sintetizador: Cria s√≠ntese final unificada

Autor: Marco
Data: Agosto 2025
"""

import json
import os
from datetime import datetime
from typing import Dict, List, Any, Tuple
from utils.console import (
    print_header, print_section, print_step, print_result, 
    log, RichProgress, RichStatus, console
)
from core.co import create_agent


# Configura√ß√µes do processamento
MAX_CONTENT_LENGTH = 3000  # Aumentado para processar mais conte√∫do
MAX_SYNTHESIS_LENGTH = 12000  # Aumentado para s√≠ntese mais completa
ENCODING = 'utf-8'


def process_with_multiple_agents(json_file: str) -> None:
    """
    Processa conte√∫do JSON usando sistema multi-agente especializado.
    
    Args:
        json_file (str): Caminho para arquivo JSON com dados coletados
        
    Raises:
        FileNotFoundError: Se o arquivo JSON n√£o for encontrado
        json.JSONDecodeError: Se o arquivo JSON estiver malformado
        
    Note:
        Gera dois arquivos de sa√≠da:
        - resumos_parciais_*.txt: An√°lises individuais por termo
        - sintese_final_*.txt: S√≠ntese unificada de todos os agentes
    """
    print_header("SISTEMA MULTI-AGENTE DE AN√ÅLISE", "Processamento inteligente com 4 agentes especializados")
    
    # Carrega e valida dados
    data = _load_json_data(json_file)
    if not data:
        return
    
    # Cria agentes especializados
    agents = _create_specialized_agents()
    
    # Processa dados e gera resumos
    partial_summaries = _process_terms_with_agents(data, agents, json_file)
    
    # Cria s√≠ntese final
    _create_final_synthesis(partial_summaries, agents['sintetizador'], json_file)
    
    # Exibe estat√≠sticas finais
    _display_processing_stats(len(partial_summaries), json_file)


def _load_json_data(json_file: str) -> Dict[str, Any]:
    """
    Carrega e valida dados do arquivo JSON.
    
    Args:
        json_file (str): Caminho para o arquivo JSON
        
    Returns:
        Dict[str, Any]: Dados carregados ou dicion√°rio vazio em caso de erro
    """
    try:
        with open(json_file, 'r', encoding=ENCODING) as file:
            data = json.load(file)
        
        log.success(f"Dados carregados com sucesso: {json_file}")
        
        # Valida estrutura b√°sica
        if 'dados' not in data:
            log.warning("Estrutura JSON inv√°lida: campo 'dados' n√£o encontrado")
            return {}
            
        return data
        
    except FileNotFoundError:
        log.error(f"Arquivo n√£o encontrado: {json_file}")
        return {}
        
    except json.JSONDecodeError as e:
        log.error(f"Erro ao decodificar JSON: {e}")
        return {}
        
    except Exception as e:
        log.error(f"Erro inesperado ao carregar arquivo: {e}")
        return {}


def _create_specialized_agents() -> Dict[str, Any]:
    """
    Cria o conjunto de agentes especializados para an√°lise.
    
    Returns:
        Dict[str, Any]: Dicion√°rio com agentes especializados
    """
    print_section("CRIANDO AGENTES ESPECIALIZADOS")
    
    with RichStatus("Configurando agentes especializados..."):
        agents = {
            'resumidor': create_agent(
            "ESPECIALISTA EM RESUMOS T√âCNICOS\n"
            "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n\n"
            "MISS√ÉO: Extrair e consolidar os pontos mais importantes do conte√∫do fornecido.\n\n"
            "INSTRU√á√ïES ESPEC√çFICAS:\n"
            "‚Ä¢ Identifique os 5-7 conceitos mais importantes\n"
            "‚Ä¢ Use linguagem t√©cnica mas acess√≠vel\n"
            "‚Ä¢ Mantenha a ordem l√≥gica do conte√∫do original\n"
            "‚Ä¢ Foque em informa√ß√µes pr√°ticas e aplic√°veis\n"
            "‚Ä¢ Elimine detalhes redundantes ou secund√°rios\n\n"
            "FORMATO DE SA√çDA:\n"
            "üìã RESUMO T√âCNICO:\n"
            "‚Ä¢ [Ponto principal 1 - detalhamento conciso]\n"
            "‚Ä¢ [Ponto principal 2 - detalhamento conciso]\n"
            "‚Ä¢ [Ponto principal 3 - detalhamento conciso]\n"
            "...\n\n"
            "Use SEMPRE portugu√™s brasileiro e seja objetivo.",
            max_tokens=600
        ),
        
        'analista': create_agent(
            "ANALISTA S√äNIOR DE CONTE√öDO T√âCNICO\n"
            "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n\n"
            "EXPERTISE: An√°lise profunda, identifica√ß√£o de patterns e extra√ß√£o de insights.\n\n"
            "RESPONSABILIDADES:\n"
            "‚Ä¢ Identificar tend√™ncias e padr√µes emergentes\n"
            "‚Ä¢ Extrair insights t√©cnicos e estrat√©gicos\n"
            "‚Ä¢ Avaliar qualidade e confiabilidade das informa√ß√µes\n"
            "‚Ä¢ Conectar conceitos e estabelecer rela√ß√µes\n"
            "‚Ä¢ Destacar implica√ß√µes pr√°ticas e aplica√ß√µes\n\n"
            "ESTRUTURA OBRIGAT√ìRIA:\n"
            "üîç AN√ÅLISE T√âCNICA:\n\n"
            "üí° INSIGHTS PRINCIPAIS:\n"
            "‚Ä¢ [Insight 1 com justificativa]\n"
            "‚Ä¢ [Insight 2 com justificativa]\n\n"
            "üìà TEND√äNCIAS IDENTIFICADAS:\n"
            "‚Ä¢ [Tend√™ncia 1 e implica√ß√µes]\n"
            "‚Ä¢ [Tend√™ncia 2 e implica√ß√µes]\n\n"
            "‚ö° IMPLICA√á√ïES PR√ÅTICAS:\n"
            "‚Ä¢ [Aplica√ß√£o pr√°tica 1]\n"
            "‚Ä¢ [Aplica√ß√£o pr√°tica 2]\n\n"
            "Use terminologia t√©cnica apropriada em portugu√™s brasileiro.",
            max_tokens=800
        ),
        
        'organizador': create_agent(
            "ESPECIALISTA EM ARQUITETURA DE INFORMA√á√ÉO\n"
            "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n\n"
            "OBJETIVO: Estruturar informa√ß√µes de forma hier√°rquica, l√≥gica e visualmente clara.\n\n"
            "METODOLOGIA:\n"
            "‚Ä¢ Criar taxonomia clara dos t√≥picos\n"
            "‚Ä¢ Estabelecer hierarquia de import√¢ncia\n"
            "‚Ä¢ Agrupar conceitos relacionados\n"
            "‚Ä¢ Usar formata√ß√£o visual consistente\n"
            "‚Ä¢ Facilitar navega√ß√£o e compreens√£o\n\n"
            "TEMPLATE OBRIGAT√ìRIO:\n"
            "üìä ESTRUTURA ORGANIZACIONAL:\n\n"
            "# üéØ T√ìPICO PRINCIPAL\n"
            "## üìù Se√ß√£o 1: [Nome da Se√ß√£o]\n"
            "### üî∏ Subse√ß√£o 1.1\n"
            "   ‚Ä¢ Ponto importante A\n"
            "   ‚Ä¢ Ponto importante B\n"
            "### üî∏ Subse√ß√£o 1.2\n"
            "   ‚Ä¢ Ponto importante C\n\n"
            "## üìù Se√ß√£o 2: [Nome da Se√ß√£o]\n"
            "### üî∏ Subse√ß√£o 2.1\n"
            "   ‚Ä¢ Ponto importante D\n\n"
            "SEMPRE use emojis, numera√ß√£o e hierarquia visual clara.",
            max_tokens=700
        ),
        
        'sintetizador': create_agent(
            "SINTETIZADOR MASTER - S√çNTESE EXECUTIVA COMPLETA\n"
            "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n\n"
            "RESPONSABILIDADE CR√çTICA: Criar s√≠ntese executiva ABRANGENTE e DETALHADA consolidando todas as an√°lises.\n\n"
            "PROCESSO AVAN√áADO DE S√çNTESE:\n"
            "‚Ä¢ CONSOLIDAR completamente resumos, an√°lises e estruturas organizacionais\n"
            "‚Ä¢ ELIMINAR redund√¢ncias mantendo informa√ß√µes essenciais\n"
            "‚Ä¢ EXPANDIR insights com contexto adicional e implica√ß√µes\n"
            "‚Ä¢ DETALHAR conclus√µes e recomenda√ß√µes estrat√©gicas\n"
            "‚Ä¢ PRODUZIR documento executivo extenso e comprehensivo\n"
            "‚Ä¢ MANTER rigor acad√™mico com linguagem profissional\n\n"
            "TEMPLATE EXECUTIVO EXPANDIDO OBRIGAT√ìRIO:\n\n"
            "# üéØ S√çNTESE EXECUTIVA COMPLETA\n\n"
            "## üìã RESUMO GERAL CONSOLIDADO\n"
            "[Vis√£o geral detalhada e consolidada do tema com contexto amplo]\n\n"
            "## üîç DESCOBERTAS PRINCIPAIS DETALHADAS\n"
            "### üíé Descoberta Cr√≠tica 1\n"
            "‚Ä¢ **Descri√ß√£o:** [Detalhamento completo]\n"
            "‚Ä¢ **Impacto:** [An√°lise de impacto espec√≠fica]\n"
            "‚Ä¢ **Evid√™ncias:** [Dados que suportam a descoberta]\n"
            "‚Ä¢ **Implica√ß√µes:** [Consequ√™ncias pr√°ticas]\n\n"
            "### üíé Descoberta Cr√≠tica 2\n"
            "‚Ä¢ **Descri√ß√£o:** [Detalhamento completo]\n"
            "‚Ä¢ **Impacto:** [An√°lise de impacto espec√≠fica]\n"
            "‚Ä¢ **Evid√™ncias:** [Dados que suportam a descoberta]\n"
            "‚Ä¢ **Implica√ß√µes:** [Consequ√™ncias pr√°ticas]\n\n"
            "### üíé Descoberta Cr√≠tica 3\n"
            "‚Ä¢ **Descri√ß√£o:** [Detalhamento completo]\n"
            "‚Ä¢ **Impacto:** [An√°lise de impacto espec√≠fica]\n"
            "‚Ä¢ **Evid√™ncias:** [Dados que suportam a descoberta]\n"
            "‚Ä¢ **Implica√ß√µes:** [Consequ√™ncias pr√°ticas]\n\n"
            "## üìä AN√ÅLISE DE TEND√äNCIAS E PADR√ïES\n"
            "### üìà Tend√™ncias Emergentes\n"
            "‚Ä¢ [Tend√™ncia 1 com an√°lise detalhada]\n"
            "‚Ä¢ [Tend√™ncia 2 com an√°lise detalhada]\n"
            "‚Ä¢ [Tend√™ncia 3 com an√°lise detalhada]\n\n"
            "### üîÑ Padr√µes Identificados\n"
            "‚Ä¢ [Padr√£o 1 e suas manifesta√ß√µes]\n"
            "‚Ä¢ [Padr√£o 2 e suas manifesta√ß√µes]\n\n"
            "## üß† INSIGHTS ESTRAT√âGICOS APROFUNDADOS\n"
            "### üí° Insight Estrat√©gico 1\n"
            "‚Ä¢ **Natureza:** [Caracteriza√ß√£o do insight]\n"
            "‚Ä¢ **Fundamenta√ß√£o:** [Base te√≥rica ou emp√≠rica]\n"
            "‚Ä¢ **Aplicabilidade:** [Contextos de aplica√ß√£o]\n"
            "‚Ä¢ **Valor Agregado:** [Benef√≠cios espec√≠ficos]\n\n"
            "### üí° Insight Estrat√©gico 2\n"
            "‚Ä¢ **Natureza:** [Caracteriza√ß√£o do insight]\n"
            "‚Ä¢ **Fundamenta√ß√£o:** [Base te√≥rica ou emp√≠rica]\n"
            "‚Ä¢ **Aplicabilidade:** [Contextos de aplica√ß√£o]\n"
            "‚Ä¢ **Valor Agregado:** [Benef√≠cios espec√≠ficos]\n\n"
            "## üéØ RECOMENDA√á√ïES ESPEC√çFICAS E ACION√ÅVEIS\n"
            "### ‚ö° A√ß√µes Imediatas (0-30 dias)\n"
            "‚Ä¢ [Recomenda√ß√£o 1 com passos espec√≠ficos]\n"
            "‚Ä¢ [Recomenda√ß√£o 2 com passos espec√≠ficos]\n\n"
            "### üìÖ A√ß√µes de M√©dio Prazo (1-6 meses)\n"
            "‚Ä¢ [Recomenda√ß√£o estrat√©gica 1]\n"
            "‚Ä¢ [Recomenda√ß√£o estrat√©gica 2]\n\n"
            "### ÔøΩ A√ß√µes de Longo Prazo (6+ meses)\n"
            "‚Ä¢ [Recomenda√ß√£o vision√°ria 1]\n"
            "‚Ä¢ [Recomenda√ß√£o vision√°ria 2]\n\n"
            "## ÔøΩüîó CONEX√ïES E INTERRELA√á√ïES\n"
            "### üåê Mapa de Conex√µes\n"
            "[An√°lise detalhada de como os diferentes aspectos se relacionam e influenciam mutuamente]\n\n"
            "### üîÑ Sistemas e Processos\n"
            "[Identifica√ß√£o de sistemas complexos e processos interconectados]\n\n"
            "## ‚ö° CONCLUS√ïES FINAIS E DIRE√á√ïES FUTURAS\n"
            "### üéØ Conclus√µes Definitivas\n"
            "[Conclus√µes consolidadas com base em toda a an√°lise]\n\n"
            "### üöÄ Dire√ß√µes Estrat√©gicas\n"
            "[Orienta√ß√µes para desenvolvimentos futuros]\n\n"
            "### üìù Considera√ß√µes Finais\n"
            "[Reflex√µes finais e contextualiza√ß√µes adicionais]\n\n"
            "EXIG√äNCIAS DE QUALIDADE PREMIUM:\n"
            "‚Ä¢ Linguagem executiva sofisticada e profissional\n"
            "‚Ä¢ Portugu√™s brasileiro formal com precis√£o t√©cnica\n"
            "‚Ä¢ M√°xima clareza, coer√™ncia e profundidade\n"
            "‚Ä¢ Foco em valor agregado m√°ximo e aplicabilidade pr√°tica\n"
            "‚Ä¢ Estrutura visual rica e hierarquizada\n"
            "‚Ä¢ Densidade informacional alta com organiza√ß√£o exemplar",
            max_tokens=2000  # Aumentado significativamente para s√≠nteses completas
        )
    }
    
    log.success(f"{len(agents)} agentes especializados criados com prompts otimizados")
    return agents


def _process_terms_with_agents(
    data: Dict[str, Any], 
    agents: Dict[str, Any], 
    json_file: str
) -> List[str]:
    """
    Processa cada termo usando a sequ√™ncia de agentes especializados.
    
    Args:
        data (Dict[str, Any]): Dados carregados do JSON
        agents (Dict[str, Any]): Agentes especializados
        json_file (str): Nome do arquivo original para nomenclatura
        
    Returns:
        List[str]: Lista de resumos parciais gerados
    """
    # Configura√ß√£o de arquivos de sa√≠da
    partial_file = _generate_output_filename(json_file, 'resumos_parciais_', '.txt')
    partial_summaries = []
    
    print_section("PROCESSAMENTO MULTI-AGENTE POR TERMO")
    
    total_terms = len(data.get('dados', {}))
    
    with open(partial_file, 'w', encoding=ENCODING) as file:
        # Cabe√ßalho do arquivo
        _write_file_header(file, "RESUMOS PARCIAIS - PIPELINE MULTI-AGENTE")
        
        term_counter = 0
        
        # Usa RichProgress para mostrar progresso
        with RichProgress(f"Processando {total_terms} termos") as progress:
            for term, pages in data.get('dados', {}).items():
                term_counter += 1
                progress.update(
                    (term_counter / total_terms) * 100,
                    f"Termo {term_counter}/{total_terms}: {term}"
                )
                
                # Extrai e prepara conte√∫do do termo
                term_content = _extract_term_content(pages)
                
                if not term_content:
                    log.warning(f"Nenhum conte√∫do v√°lido encontrado para '{term}'")
                    continue
                
                # Aplica pipeline de agentes
                term_result = _apply_agent_pipeline(term, term_content, agents)
                
                # Salva resultado parcial
                _write_term_result(file, term, term_result)
                
                # Adiciona √† lista para s√≠ntese final
                partial_summaries.append(_format_partial_summary(term, term_result))
                
                log.success(f"Termo '{term}' processado com sucesso")
    
    log.info(f"Resumos parciais salvos em: {partial_file}")
    return partial_summaries


def _extract_term_content(pages: List[Dict[str, Any]]) -> str:
    """
    Extrai e combina conte√∫do v√°lido de todas as p√°ginas de um termo.
    
    Args:
        pages (List[Dict[str, Any]]): Lista de p√°ginas do termo
        
    Returns:
        str: Conte√∫do combinado e limitado
    """
    valid_content = []
    
    for page in pages:
        if page.get('status') == 'sucesso':
            # Tenta m√∫ltiplos campos de conte√∫do
            text = (
                page.get('conteudo_texto') or 
                page.get('conteudo', '') or 
                page.get('texto', '')
            )
            
            # Filtra conte√∫do muito pequeno
            if len(text) > 100:
                # Limita tamanho para evitar sobrecarga
                limited_text = text[:MAX_CONTENT_LENGTH] if len(text) > MAX_CONTENT_LENGTH else text
                valid_content.append(limited_text)
    
    return "\n\n".join(valid_content)


def _apply_agent_pipeline(
    term: str, 
    content: str, 
    agents: Dict[str, Any]
) -> Dict[str, str]:
    """
    Aplica sequ√™ncia de agentes especializados em um termo.
    
    Args:
        term (str): Nome do termo sendo processado
        content (str): Conte√∫do combinado do termo
        agents (Dict[str, Any]): Agentes especializados
        
    Returns:
        Dict[str, str]: Resultados de cada agente
    """
    print(f"      üîÑ Executando pipeline multi-agente otimizado...")
    
    # Preparar contexto rico para os agentes
    content_stats = {
        'tamanho': len(content),
        'palavras': len(content.split()),
        'linhas': len(content.splitlines())
    }
    
    context_header = f"""
CONTEXTO DO PROCESSAMENTO:
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
üè∑Ô∏è  TERMO: {term}
üìä ESTAT√çSTICAS: {content_stats['palavras']} palavras, {content_stats['linhas']} linhas
üéØ OBJETIVO: An√°lise t√©cnica completa e estruturada

"""
    
    # Agente 1: Resumidor
    print(f"      ü§ñ Agente Resumidor processando...")
    summary_prompt = f"{context_header}TAREFA: Resuma os pontos t√©cnicos mais importantes do conte√∫do abaixo.\n\nCONTE√öDO:\n{content}"
    summary = agents['resumidor'](summary_prompt)
    
    # Agente 2: Analista (com contexto do resumo)
    print(f"      ü§ñ Agente Analista processando...")
    analysis_prompt = f"""{context_header}TAREFA: Analise profundamente o conte√∫do, identificando insights e padr√µes.

RESUMO INICIAL DISPON√çVEL:
{summary}

CONTE√öDO COMPLETO PARA AN√ÅLISE:
{content}

Foque em insights n√£o cobertos no resumo e conex√µes importantes."""
    
    analysis = agents['analista'](analysis_prompt)
    
    # Agente 3: Organizador (com contexto acumulado)
    print(f"      ü§ñ Agente Organizador processando...")
    organization_prompt = f"""{context_header}TAREFA: Organize hierarquicamente todas as informa√ß√µes dispon√≠veis.

RESUMO T√âCNICO:
{summary}

AN√ÅLISE DETALHADA:
{analysis}

CONTE√öDO ORIGINAL:
{content[:1500]}...

Crie uma estrutura visual clara que integre resumo, an√°lise e conte√∫do original."""
    
    organization = agents['organizador'](organization_prompt)
    
    return {
        'resumo': summary,
        'analise': analysis,
        'organizacao': organization
    }


def _create_final_synthesis(
    partial_summaries: List[str], 
    synthesizer: Any, 
    json_file: str
) -> None:
    """
    Cria s√≠ntese final usando o agente sintetizador.
    
    Args:
        partial_summaries (List[str]): Resumos parciais de todos os termos
        synthesizer (Any): Agente sintetizador
        json_file (str): Nome do arquivo original
    """
    print("üéØ Criando S√≠ntese Final Executiva...")
    
    if not partial_summaries:
        print("‚ùå Nenhum resumo parcial dispon√≠vel para s√≠ntese")
        return
    
    # Combina todos os resumos parciais
    combined_content = "\n\n" + "="*60 + "\n\n".join(partial_summaries)
    
    # Limita conte√∫do para evitar sobrecarga do agente
    if len(combined_content) > MAX_SYNTHESIS_LENGTH:
        # Trunca inteligentemente mantendo resumos completos
        truncated_summaries = []
        current_length = 0
        
        for summary in partial_summaries:
            if current_length + len(summary) <= MAX_SYNTHESIS_LENGTH:
                truncated_summaries.append(summary)
                current_length += len(summary)
            else:
                # Adiciona resumo parcial do √∫ltimo item
                remaining_space = MAX_SYNTHESIS_LENGTH - current_length - 100
                if remaining_space > 200:
                    truncated_summaries.append(summary[:remaining_space] + "\n\n[RESUMO TRUNCADO]")
                break
        
        combined_content = "\n\n" + "="*60 + "\n\n".join(truncated_summaries)
        print(f"   ‚ö†Ô∏è Conte√∫do otimizado: {len(truncated_summaries)} de {len(partial_summaries)} resumos inclu√≠dos")
    
    # Estat√≠sticas para contexto
    stats = {
        'total_termos': len(partial_summaries),
        'total_caracteres': len(combined_content),
        'arquivo_origem': json_file
    }
    
    # Prompt otimizado para s√≠ntese executiva
    synthesis_prompt = f"""
BRIEFING EXECUTIVO PARA S√çNTESE FINAL
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

üìä ESTAT√çSTICAS DO PROJETO:
‚Ä¢ Total de termos analisados: {stats['total_termos']}
‚Ä¢ Volume de conte√∫do processado: {stats['total_caracteres']:,} caracteres
‚Ä¢ Fonte de dados: {stats['arquivo_origem']}

üéØ MISS√ÉO CR√çTICA:
Voc√™ recebeu an√°lises especializadas de m√∫ltiplos agentes sobre diferentes aspectos de um tema.
Sua tarefa √© criar uma S√çNTESE EXECUTIVA DEFINITIVA que integre todos os insights de forma coerente.

üìã AN√ÅLISES DOS AGENTES ESPECIALIZADOS:
{combined_content}

üéØ INSTRU√á√ïES PARA S√çNTESE FINAL:
‚Ä¢ Integre TODOS os insights dos agentes especializados
‚Ä¢ Elimine redund√¢ncias mantendo informa√ß√µes √∫nicas
‚Ä¢ Crie narrativa coerente e fluida
‚Ä¢ Destaque descobertas mais importantes
‚Ä¢ Formule recomenda√ß√µes pr√°ticas e aplic√°veis
‚Ä¢ Use formata√ß√£o executiva profissional
‚Ä¢ Mantenha tom t√©cnico mas acess√≠vel

ENTREGUE uma s√≠ntese que demonstre o valor agregado de todo o processo de an√°lise multi-agente.
"""
    
    # Gera s√≠ntese final
    final_synthesis = synthesizer(synthesis_prompt)
    
    # Salva s√≠ntese final
    final_file = _generate_output_filename(json_file, 'sintese_final_', '.txt')
    
    with open(final_file, 'w', encoding=ENCODING) as file:
        _write_file_header(file, "S√çNTESE FINAL - SISTEMA MULTI-AGENTE OTIMIZADO")
        file.write(final_synthesis)
        file.write("\n\n" + "="*80 + "\n")
        file.write(f"üìä METADATA DO PROCESSAMENTO AVAN√áADO\n")
        file.write(f"   ‚Ä¢ Termos processados: {stats['total_termos']}\n")
        file.write(f"   ‚Ä¢ Agentes utilizados: 4 (Resumidor, Analista, Organizador, Sintetizador)\n")
        file.write(f"   ‚Ä¢ Volume processado: {stats['total_caracteres']:,} caracteres\n")
        file.write(f"   ‚Ä¢ Arquivo fonte: {stats['arquivo_origem']}\n")
        file.write(f"   ‚Ä¢ Tokens otimizados: Sistema adaptativo\n")
        file.write(f"   ‚Ä¢ Data/Hora: {datetime.now().strftime('%d/%m/%Y %H:%M:%S')}\n")
        file.write(f"   ‚Ä¢ Vers√£o do sistema: 2.0 (Clean Code + IA Otimizada)\n")
    
    print(f"üéâ S√≠ntese final otimizada salva em: {final_file}")
    
    # Exibe pr√©via da s√≠ntese no terminal
    print("\n" + "="*80)
    print("üéØ PR√âVIA DA S√çNTESE FINAL OTIMIZADA")
    print("="*80)
    # Mostra mais conte√∫do na pr√©via
    preview_length = 800
    print(final_synthesis[:preview_length] + "..." if len(final_synthesis) > preview_length else final_synthesis)
    print("="*80)


def _generate_output_filename(original_file: str, prefix: str, extension: str) -> str:
    """Gera nome de arquivo de sa√≠da baseado no arquivo original."""
    return original_file.replace('dados_', prefix).replace('.json', extension)


def _write_file_header(file, title: str) -> None:
    """Escreve cabe√ßalho padr√£o nos arquivos de sa√≠da."""
    file.write(f"{title}\n")
    file.write(f"Data: {datetime.now().strftime('%d/%m/%Y %H:%M:%S')}\n")
    file.write("="*80 + "\n\n")


def _write_term_result(file, term: str, result: Dict[str, str]) -> None:
    """Escreve resultado de um termo no arquivo de resumos parciais."""
    formatted_result = f"""
TERMO: {term}
{"="*50}

üìã RESUMO:
{result['resumo']}

üîç AN√ÅLISE:
{result['analise']}

üìä ORGANIZA√á√ÉO:
{result['organizacao']}

{"="*80}

"""
    file.write(formatted_result)
    file.flush()  # For√ßa escrita imediata


def _format_partial_summary(term: str, result: Dict[str, str]) -> str:
    """Formata resumo parcial para s√≠ntese final."""
    return (
        f"TERMO: {term}\n"
        f"RESUMO: {result['resumo']}\n"
        f"AN√ÅLISE: {result['analise']}\n"
        f"ORGANIZA√á√ÉO: {result['organizacao']}"
    )


def _display_processing_stats(terms_processed: int, json_file: str) -> None:
    """Exibe estat√≠sticas finais do processamento."""
    print(f"\n‚úÖ Processamento Multi-Agente Conclu√≠do!")
    print(f"üìä Estat√≠sticas Finais:")
    print(f"   üìù Termos processados: {terms_processed}")
    print(f"   ü§ñ Agentes utilizados: 4 (Pipeline especializado)")
    print(f"   üìÑ Arquivos gerados: 2 (resumos parciais + s√≠ntese final)")
    print(f"   üìÇ Arquivo fonte: {json_file}")
    print(f"   ‚è±Ô∏è Processamento conclu√≠do: {datetime.now().strftime('%H:%M:%S')}")


def create_multi_agent_summary(json_file: str) -> None:
    """
    Fun√ß√£o principal para processar arquivo JSON com sistema multi-agente.
    
    Args:
        json_file (str): Caminho para arquivo JSON com dados coletados
        
    Note:
        Esta √© a interface p√∫blica do m√≥dulo.
        Alias para compatibilidade com c√≥digo existente.
    """
    process_with_multiple_agents(json_file)


# Aliases para compatibilidade com c√≥digo existente
processar_com_multiplos_agentes = process_with_multiple_agents
criar_resumo_com_agentes = create_multi_agent_summary


if __name__ == "__main__":
    # Teste do m√≥dulo quando executado diretamente
    print("üß™ Testando Sistema Multi-Agente...")
    
    # Arquivo de teste (deve existir)
    test_file = "dados_python_programa√ß√£o.json"
    
    if os.path.exists(test_file):
        create_multi_agent_summary(test_file)
    else:
        print(f"‚ùå Arquivo de teste n√£o encontrado: {test_file}")
        print("üí° Execute primeiro uma coleta de dados para gerar o arquivo JSON.")
